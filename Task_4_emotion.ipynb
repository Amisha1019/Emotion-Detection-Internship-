{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 8629206,
          "sourceType": "datasetVersion",
          "datasetId": 5166572
        }
      ],
      "dockerImageVersionId": 31192,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "Task 4 emotion ",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amisha1019/Emotion-Detection-Internship-/blob/main/Task_4_emotion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "nexdatafrank_millions_of_foreign_face_data_single_image_path = kagglehub.dataset_download('nexdatafrank/millions-of-foreign-face-data-single-image')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "ZCpQKKnHVcZO",
        "outputId": "2fad82c7-ff76-4b55-8265-04fb05d18700",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/nexdatafrank/millions-of-foreign-face-data-single-image?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.3M/26.3M [00:00<00:00, 51.9MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-19T06:54:44.014048Z",
          "iopub.execute_input": "2025-11-19T06:54:44.014252Z",
          "iopub.status.idle": "2025-11-19T06:54:44.293827Z",
          "shell.execute_reply.started": "2025-11-19T06:54:44.014225Z",
          "shell.execute_reply": "2025-11-19T06:54:44.293164Z"
        },
        "id": "F0T43Ze2VcZW"
      },
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit opencv-python-headless deepface scikit-learn numpy pillow\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-19T06:54:44.294496Z",
          "iopub.execute_input": "2025-11-19T06:54:44.294841Z",
          "iopub.status.idle": "2025-11-19T06:54:47.36339Z",
          "shell.execute_reply.started": "2025-11-19T06:54:44.294822Z",
          "shell.execute_reply": "2025-11-19T06:54:47.362643Z"
        },
        "id": "hG_MPPNJVcZY",
        "outputId": "4f48a25c-8540-43f2-b9ca-e90329fa411b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.51.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Collecting deepface\n",
            "  Downloading deepface-0.0.95-py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.0)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow<22,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.5.1)\n",
            "Requirement already satisfied: gdown>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from deepface) (5.2.0)\n",
            "Requirement already satisfied: tqdm>=4.30.0 in /usr/local/lib/python3.12/dist-packages (from deepface) (4.67.1)\n",
            "Requirement already satisfied: opencv-python>=4.5.5.64 in /usr/local/lib/python3.12/dist-packages (from deepface) (4.12.0.88)\n",
            "Requirement already satisfied: tensorflow>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from deepface) (2.19.0)\n",
            "Requirement already satisfied: keras>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from deepface) (3.10.0)\n",
            "Requirement already satisfied: Flask>=1.1.2 in /usr/local/lib/python3.12/dist-packages (from deepface) (3.1.2)\n",
            "Collecting flask-cors>=4.0.1 (from deepface)\n",
            "  Downloading flask_cors-6.0.1-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting mtcnn>=0.1.0 (from deepface)\n",
            "  Downloading mtcnn-1.0.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting retina-face>=0.0.14 (from deepface)\n",
            "  Downloading retina_face-0.0.17-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting fire>=0.4.0 (from deepface)\n",
            "  Downloading fire-0.7.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting gunicorn>=20.1.0 (from deepface)\n",
            "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.11.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from fire>=0.4.0->deepface) (3.2.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from Flask>=1.1.2->deepface) (2.2.0)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from Flask>=1.1.2->deepface) (3.0.3)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from Flask>=1.1.2->deepface) (3.1.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown>=3.10.1->deepface) (4.13.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown>=3.10.1->deepface) (3.20.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from keras>=2.2.0->deepface) (1.4.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=2.2.0->deepface) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=2.2.0->deepface) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from keras>=2.2.0->deepface) (3.15.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=2.2.0->deepface) (0.17.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.12/dist-packages (from keras>=2.2.0->deepface) (0.5.3)\n",
            "Collecting lz4>=4.3.3 (from mtcnn>=0.1.0->deepface)\n",
            "  Downloading lz4-4.4.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.10.5)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->deepface) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->deepface) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->deepface) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->deepface) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->deepface) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->deepface) (3.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->deepface) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->deepface) (1.17.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->deepface) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->deepface) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->deepface) (2.19.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow>=1.9.0->deepface) (0.45.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.28.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow>=1.9.0->deepface) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow>=1.9.0->deepface) (0.7.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown>=3.10.1->deepface) (2.8)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (1.7.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=2.2.0->deepface) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=2.2.0->deepface) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=2.2.0->deepface) (0.1.2)\n",
            "Downloading streamlit-1.51.0-py3-none-any.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading deepface-0.0.95-py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.3/128.3 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fire-0.7.1-py3-none-any.whl (115 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.9/115.9 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading flask_cors-6.0.1-py3-none-any.whl (13 kB)\n",
            "Downloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mtcnn-1.0.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m78.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m97.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading retina_face-0.0.17-py3-none-any.whl (25 kB)\n",
            "Downloading lz4-4.4.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lz4, gunicorn, fire, pydeck, mtcnn, flask-cors, streamlit, retina-face, deepface\n",
            "Successfully installed deepface-0.0.95 fire-0.7.1 flask-cors-6.0.1 gunicorn-23.0.0 lz4-4.4.5 mtcnn-1.0.0 pydeck-0.9.1 retina-face-0.0.17 streamlit-1.51.0\n"
          ]
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-18T13:48:44.602276Z",
          "iopub.execute_input": "2025-11-18T13:48:44.60248Z"
        },
        "id": "aSjzofMuVcZZ",
        "outputId": "0ffbf3a7-c3ed-4dc8-d958-d106c5620f05"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "/bin/bash: line 1: streamlit: command not found\n\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K\u001b[1G\u001b[0JNeed to install the following packages:\nlocaltunnel@2.0.2\nOk to proceed? (y) \u001b[20G",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-19T07:00:14.860357Z",
          "iopub.execute_input": "2025-11-19T07:00:14.860615Z",
          "iopub.status.idle": "2025-11-19T07:00:17.68428Z",
          "shell.execute_reply.started": "2025-11-19T07:00:14.860594Z",
          "shell.execute_reply": "2025-11-19T07:00:17.683455Z"
        },
        "id": "pv-bCYJWVcZa",
        "outputId": "53e8e1fd-51cb-43ff-b7bc-4a24d5011595",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.12/dist-packages (1.51.0)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<13,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow<22,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.5.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.11.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.10.5)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.28.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n"
          ]
        }
      ],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "source": [
        "# Nationality Detection + Emotion + Age + Dress Color\n",
        "# Streamlit single-file app that:\n",
        "# - Lets user upload an image (preview shown)\n",
        "# - Detects face, predicts nationality (using a trained PyTorch model if available)\n",
        "# - Predicts emotion and age using DeepFace (fallback on simple models if DeepFace unavailable)\n",
        "# - Predicts dominant dress color by sampling below the face bounding box\n",
        "# - Conditional outputs:\n",
        "# * If nationality == 'Indian' -> show nationality, age, emotion, dress color\n",
        "# * If nationality == 'United States' or 'USA' -> show age, emotion\n",
        "# * If nationality is an African nationality (user-definable list) -> show emotion and dress color\n",
        "# * Else -> show nationality and emotion\n",
        "#\n",
        "# Notes for the user:\n",
        "# - Provide a trained nationality classifier at './nationality_model.pth' or put a weights file in\n",
        "# the Kaggle input path (for example: '/kaggle/input/nationality_model/nationality_model.pth').\n",
        "# - The dataset path suggested by you: '/kaggle/input/millions-of-foreign-face-data-single-image'\n",
        "# This script assumes the dataset can be used as an ImageFolder or you can provide a CSV mapping.\n",
        "# - This file contains both inference (GUI) and a training helper function. Training on large\n",
        "# datasets should be done on a GPU notebook (Kaggle/Colab) and may take many hours."
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-19T07:00:47.166884Z",
          "iopub.execute_input": "2025-11-19T07:00:47.167156Z",
          "iopub.status.idle": "2025-11-19T07:00:47.170562Z",
          "shell.execute_reply.started": "2025-11-19T07:00:47.167136Z",
          "shell.execute_reply": "2025-11-19T07:00:47.170051Z"
        },
        "id": "2JLaS9_AVcZc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-19T13:17:02.349307Z",
          "iopub.execute_input": "2025-11-19T13:17:02.350593Z",
          "iopub.status.idle": "2025-11-19T13:17:10.98905Z",
          "shell.execute_reply.started": "2025-11-19T13:17:02.350545Z",
          "shell.execute_reply": "2025-11-19T13:17:10.987343Z"
        },
        "id": "aawL2iXnVcZd",
        "outputId": "d13fafe7-0fcc-4b3c-8a22-98cdb7f9fc6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.12/dist-packages (1.51.0)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<13,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow<22,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.5.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.11.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.10.5)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.28.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n"
          ]
        }
      ],
      "execution_count": 5
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import io\n",
        "import sys\n",
        "import time\n",
        "from typing import Tuple, Optional, List\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image, ImageOps\n",
        "\n",
        "import streamlit as st"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-19T13:18:42.841125Z",
          "iopub.execute_input": "2025-11-19T13:18:42.841479Z",
          "iopub.status.idle": "2025-11-19T13:18:43.910499Z",
          "shell.execute_reply.started": "2025-11-19T13:18:42.841448Z",
          "shell.execute_reply": "2025-11-19T13:18:43.90905Z"
        },
        "id": "HlGJgUnkVcZe"
      },
      "outputs": [],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "source": [
        "# try optional packages; if missing, the app will show instructions\n",
        "try:\n",
        "    import torch\n",
        "    import torch.nn as nn\n",
        "    import torch.optim as optim\n",
        "    from torch.utils.data import DataLoader\n",
        "    import torchvision\n",
        "    from torchvision import transforms, models\n",
        "except Exception:\n",
        "    torch = None"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-19T13:18:54.381373Z",
          "iopub.execute_input": "2025-11-19T13:18:54.381937Z",
          "iopub.status.idle": "2025-11-19T13:19:05.147634Z",
          "shell.execute_reply.started": "2025-11-19T13:18:54.381907Z",
          "shell.execute_reply": "2025-11-19T13:19:05.145877Z"
        },
        "id": "JqTEOOzQVcZe"
      },
      "outputs": [],
      "execution_count": 7
    },
    {
      "cell_type": "code",
      "source": [
        "# DeepFace is optional but recommended for age/emotion convenience\n",
        "try:\n",
        "    from deepface import DeepFace\n",
        "except Exception:\n",
        "    DeepFace = None\n",
        "\n",
        "import cv2\n",
        "from sklearn.cluster import KMeans\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-19T13:19:17.250672Z",
          "iopub.execute_input": "2025-11-19T13:19:17.251288Z",
          "iopub.status.idle": "2025-11-19T13:19:18.803297Z",
          "shell.execute_reply.started": "2025-11-19T13:19:17.251257Z",
          "shell.execute_reply": "2025-11-19T13:19:18.80219Z"
        },
        "id": "k3eHiGSkVcZf",
        "outputId": "d2482341-adc5-469e-bf9c-e6c80c366c3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25-11-19 13:41:37 - Directory /root/.deepface has been created\n",
            "25-11-19 13:41:37 - Directory /root/.deepface/weights has been created\n"
          ]
        }
      ],
      "execution_count": 8
    },
    {
      "cell_type": "code",
      "source": [
        "def pil_to_cv2(img_pil: Image.Image) -> np.ndarray:\n",
        "    cv_img = np.array(img_pil.convert('RGB'))\n",
        "    # Convert RGB to BGR\n",
        "    return cv_img[:, :, ::-1].copy()\n",
        "\n",
        "\n",
        "def cv2_to_pil(img_cv: np.ndarray) -> Image.Image:\n",
        "    # BGR to RGB\n",
        "    return Image.fromarray(img_cv[:, :, ::-1])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-19T13:19:43.721484Z",
          "iopub.execute_input": "2025-11-19T13:19:43.722076Z",
          "iopub.status.idle": "2025-11-19T13:19:43.731392Z",
          "shell.execute_reply.started": "2025-11-19T13:19:43.722048Z",
          "shell.execute_reply": "2025-11-19T13:19:43.730016Z"
        },
        "id": "EzP3V7Y8VcZf"
      },
      "outputs": [],
      "execution_count": 9
    },
    {
      "cell_type": "code",
      "source": [
        "def get_face_detector(net=None):\n",
        "    # net is a cv2.dnn readNet if provided; otherwise try to use cv2.CascadeClassifier as fallback\n",
        "    if net is not None:\n",
        "        return net\n",
        "    # fallback to Haar cascade available in OpenCV package\n",
        "    haar_xml = cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'\n",
        "    if os.path.exists(haar_xml):\n",
        "        cascade = cv2.CascadeClassifier(haar_xml)\n",
        "        return cascade\n",
        "    return None\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-19T13:19:46.534562Z",
          "iopub.execute_input": "2025-11-19T13:19:46.535071Z",
          "iopub.status.idle": "2025-11-19T13:19:46.542009Z",
          "shell.execute_reply.started": "2025-11-19T13:19:46.535046Z",
          "shell.execute_reply": "2025-11-19T13:19:46.540196Z"
        },
        "id": "W6gaoFBFVcZg"
      },
      "outputs": [],
      "execution_count": 10
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_faces(image_bgr: np.ndarray, detector=None, conf_threshold=0.5) -> List[Tuple[int,int,int,int]]:\n",
        "    \"\"\"Return list of bounding boxes (x, y, w, h) in image coordinates.\"\"\"\n",
        "    h, w = image_bgr.shape[:2]\n",
        "    boxes = []\n",
        "    if detector is None:\n",
        "        detector = get_face_detector()\n",
        "\n",
        "    # If detector is a CascadeClassifier\n",
        "    if isinstance(detector, cv2.CascadeClassifier):\n",
        "        gray = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY)\n",
        "        rects = detector.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30,30))\n",
        "        for (x,y,ww,hh) in rects:\n",
        "            boxes.append((x,y,ww,hh))\n",
        "        return boxes\n",
        "         # else: try DNN detection (user can supply a dnn net)\n",
        "    try:\n",
        "        blob = cv2.dnn.blobFromImage(image_bgr, 1.0, (300,300),(104.0,177.0,123.0))\n",
        "        detector.setInput(blob)\n",
        "        detections = detector.forward()\n",
        "        for i in range(0, detections.shape[2]):\n",
        "            confidence = detections[0,0,i,2]\n",
        "            if confidence > conf_threshold:\n",
        "                box = detections[0,0,i,3:7] * np.array([w, h, w, h])\n",
        "                (startX, startY, endX, endY) = box.astype(\"int\")\n",
        "                startX = max(0, startX); startY = max(0, startY)\n",
        "                endX = min(w-1, endX); endY = min(h-1, endY)\n",
        "                boxes.append((startX, startY, endX-startX, endY-startY))\n",
        "        return boxes\n",
        "    except Exception:\n",
        "        return boxes"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-19T13:19:52.095662Z",
          "iopub.execute_input": "2025-11-19T13:19:52.096134Z",
          "iopub.status.idle": "2025-11-19T13:19:52.108721Z",
          "shell.execute_reply.started": "2025-11-19T13:19:52.096103Z",
          "shell.execute_reply": "2025-11-19T13:19:52.106997Z"
        },
        "id": "kIVWYHrfVcZg"
      },
      "outputs": [],
      "execution_count": 11
    },
    {
      "cell_type": "code",
      "source": [
        "def crop_region(image_bgr: np.ndarray, box: Tuple[int,int,int,int], pad: float=0.15) -> np.ndarray:\n",
        "    x,y,w,h = box\n",
        "    H,W = image_bgr.shape[:2]\n",
        "    pad_x = int(w*pad)\n",
        "    pad_y = int(h*pad)\n",
        "    x0 = max(0, x-pad_x); y0 = max(0, y-pad_y)\n",
        "    x1 = min(W, x+w+pad_x); y1 = min(H, y+h+pad_y)\n",
        "    return image_bgr[y0:y1, x0:x1]\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-19T13:19:57.509451Z",
          "iopub.execute_input": "2025-11-19T13:19:57.509992Z",
          "iopub.status.idle": "2025-11-19T13:19:57.516857Z",
          "shell.execute_reply.started": "2025-11-19T13:19:57.509962Z",
          "shell.execute_reply": "2025-11-19T13:19:57.515646Z"
        },
        "id": "H1vrQ26kVcZg"
      },
      "outputs": [],
      "execution_count": 12
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dominant_color(image_bgr: np.ndarray, k=3) -> Tuple[int,int,int]:\n",
        "    \"\"\"Return dominant color as RGB tuple sampled from BGR image.\"\"\"\n",
        "    # Convert to RGB\n",
        "    img = image_bgr[:, :, ::-1]\n",
        "    img = img.reshape((-1, 3)).astype(np.float32)\n",
        "    # sample to speed up\n",
        "    if img.shape[0] > 2000:\n",
        "        idx = np.random.choice(img.shape[0], 2000, replace=False)\n",
        "        sample = img[idx]\n",
        "    else:\n",
        "        sample = img\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42).fit(sample)\n",
        "    counts = np.bincount(kmeans.labels_)\n",
        "    center = kmeans.cluster_centers_[np.argmax(counts)].astype(int)\n",
        "    return tuple(int(c) for c in center)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-19T13:20:22.770944Z",
          "iopub.execute_input": "2025-11-19T13:20:22.771234Z",
          "iopub.status.idle": "2025-11-19T13:20:22.778932Z",
          "shell.execute_reply.started": "2025-11-19T13:20:22.771215Z",
          "shell.execute_reply": "2025-11-19T13:20:22.777627Z"
        },
        "id": "EmLnsZvBVcZg"
      },
      "outputs": [],
      "execution_count": 13
    },
    {
      "cell_type": "code",
      "source": [
        "def rgb_to_name(rgb: Tuple[int,int,int]) -> str:\n",
        "    # Very simple mapping using hue ranges: convert to HSV and map to color names.\n",
        "    import colorsys\n",
        "    r,g,b = rgb\n",
        "    h,s,v = colorsys.rgb_to_hsv(r/255.0,g/255.0,b/255.0)\n",
        "    hue = h*360\n",
        "    if v < 0.2:\n",
        "        return 'black (very dark)'\n",
        "    if s < 0.2:\n",
        "        if v > 0.9:\n",
        "            return 'white'\n",
        "        else:\n",
        "            return 'gray'\n",
        "    if hue < 15 or hue >= 345:\n",
        "        return 'red'\n",
        "    if hue < 45:\n",
        "        return 'orange'\n",
        "    if hue < 70:\n",
        "        return 'yellow'\n",
        "    if hue < 165:\n",
        "        return 'green'\n",
        "    if hue < 255:\n",
        "        return 'blue'\n",
        "    if hue < 285:\n",
        "        return 'purple'\n",
        "    return 'pink'"
      ],
      "metadata": {
        "trusted": true,
        "id": "Q04AkZQ7VcZh"
      },
      "outputs": [],
      "execution_count": 14
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleNationalityClassifier(nn.Module):\n",
        "    def __init__(self, num_classes:int):\n",
        "        super().__init__()\n",
        "        self.backbone = models.resnet18(pretrained=True)\n",
        "        in_features = self.backbone.fc.in_features\n",
        "        self.backbone.fc = nn.Linear(in_features, num_classes)\n",
        "\n",
        "    def forward(self,x):\n",
        "        return self.backbone(x)\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-19T13:22:14.398704Z",
          "iopub.execute_input": "2025-11-19T13:22:14.399067Z",
          "iopub.status.idle": "2025-11-19T13:22:14.405061Z",
          "shell.execute_reply.started": "2025-11-19T13:22:14.399041Z",
          "shell.execute_reply": "2025-11-19T13:22:14.404008Z"
        },
        "id": "5o7dEzOkVcZh"
      },
      "outputs": [],
      "execution_count": 15
    },
    {
      "cell_type": "code",
      "source": [
        "def load_nationality_model(model_path: str, device: torch.device, num_classes:int=10):\n",
        "    if torch is None:\n",
        "        return None\n",
        "    model = SimpleNationalityClassifier(num_classes)\n",
        "    if os.path.exists(model_path):\n",
        "        try:\n",
        "            state = torch.load(model_path, map_location=device)\n",
        "            # support both state_dict and raw model\n",
        "            if isinstance(state, dict) and 'state_dict' in state:\n",
        "                model.load_state_dict(state['state_dict'])\n",
        "            elif isinstance(state, dict) and set(state.keys()).issuperset({'fc.weight','fc.bias'}) or True:\n",
        "                # assume raw state_dict\n",
        "                try:\n",
        "                    model.load_state_dict(state)\n",
        "                except Exception:\n",
        "                    # partial load: ignore\n",
        "                    pass\n",
        "            else:\n",
        "                # if object saved\n",
        "                model = state\n",
        "        except Exception as e:\n",
        "            st.warning(f\"Could not load model: {e}\")\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    return model"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-19T13:22:45.308563Z",
          "iopub.execute_input": "2025-11-19T13:22:45.308927Z",
          "iopub.status.idle": "2025-11-19T13:22:45.318239Z",
          "shell.execute_reply.started": "2025-11-19T13:22:45.308901Z",
          "shell.execute_reply": "2025-11-19T13:22:45.315686Z"
        },
        "id": "2xfZDYWqVcZh"
      },
      "outputs": [],
      "execution_count": 16
    },
    {
      "cell_type": "code",
      "source": [
        "def train_nationality_classifier(dataset_root: str, output_path: str, epochs=5, batch_size=32, lr=1e-4, num_workers=4):\n",
        "    if torch is None:\n",
        "        raise RuntimeError('PyTorch not available in this environment')\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    # assume dataset_root organized in subfolders per nationality (ImageFolder)\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224,224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "    ])\n",
        "    dataset = torchvision.datasets.ImageFolder(dataset_root, transform=transform)\n",
        "    num_classes = len(dataset.classes)\n",
        "    st.write(f'Training with {len(dataset)} images across {num_classes} classes')\n",
        "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "    model = SimpleNationalityClassifier(num_classes).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running = 0.0\n",
        "        for i, (inputs, labels) in enumerate(loader):\n",
        "            inputs = inputs.to(device); labels = labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running += loss.item()\n",
        "            if i % 50 == 0:\n",
        "                st.write(f'Epoch {epoch+1}/{epochs} step {i} loss {running/(i+1):.4f}')\n",
        "        # save checkpoint\n",
        "        torch.save({'state_dict': model.state_dict(), 'classes': dataset.classes}, output_path)\n",
        "        st.write(f'Saved checkpoint to {output_path}')\n",
        "    return output_path"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-19T13:23:56.594869Z",
          "iopub.execute_input": "2025-11-19T13:23:56.595262Z",
          "iopub.status.idle": "2025-11-19T13:23:56.608571Z",
          "shell.execute_reply.started": "2025-11-19T13:23:56.595236Z",
          "shell.execute_reply": "2025-11-19T13:23:56.606968Z"
        },
        "id": "uYvyeQ8wVcZi"
      },
      "outputs": [],
      "execution_count": 17
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_nationality_from_image(model, device, pil_img: Image.Image, class_names: List[str]) -> Tuple[str,float]:\n",
        "    if model is None or torch is None:\n",
        "        return 'Unknown', 0.0\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224,224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "    ])\n",
        "    x = transform(pil_img).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        out = model(x)\n",
        "        probs = torch.nn.functional.softmax(out, dim=1).cpu().numpy()[0]\n",
        "        idx = int(np.argmax(probs))\n",
        "        return class_names[idx], float(probs[idx])\n",
        "\n",
        "st.set_page_config(page_title='Nationality + Emotion Detector', layout='wide')\n",
        "st.title('Nationality Detection Model — GUI')\n",
        "st.markdown('/kaggle/input/millions-of-foreign-face-data-single-image/00000007_Brazil_female_young.jpg')\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-19T13:25:24.963807Z",
          "iopub.execute_input": "2025-11-19T13:25:24.9642Z",
          "iopub.status.idle": "2025-11-19T13:25:24.985102Z",
          "shell.execute_reply.started": "2025-11-19T13:25:24.964175Z",
          "shell.execute_reply": "2025-11-19T13:25:24.983674Z"
        },
        "id": "StV6_INzVcZi",
        "outputId": "2a958eb0-7fae-4d9e-a976-697ba8fec750",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-11-19 13:42:11.191 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-19 13:42:11.194 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-19 13:42:11.494 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.12/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n",
            "2025-11-19 13:42:11.495 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-19 13:42:11.497 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-19 13:42:11.500 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-19 13:42:11.502 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-19 13:42:11.502 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeltaGenerator()"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "execution_count": 18
    },
    {
      "cell_type": "code",
      "source": [
        "col1, col2 = st.columns([1,1])\n",
        "\n",
        "with col1:\n",
        "    uploaded = st.file_uploader('/kaggle/input/millions-of-foreign-face-data-single-image/00000047_American_male_young.jpg', type=['jpg','jpeg','png'])\n",
        "    dataset_path = st.text_input('Optional: dataset root (for training) or folder with classes', value='/kaggle/input/millions-of-foreign-face-data-single-image')\n",
        "    model_path = st.text_input('Optional: nationality model path (weights)', value='./nationality_model.pth')\n",
        "    run_train = st.button('Train nationality classifier (use with caution)')\n",
        "\n",
        "with col2:\n",
        "    st.write('Model / Environment status:')\n",
        "    st.write(f\"PyTorch available: {'Yes' if torch is not None else 'No'}\")\n",
        "    st.write(f\"DeepFace available: {'Yes' if DeepFace is not None else 'No'}\")\n",
        "    st.write('Face detector: Haar cascade fallback used')\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-19T13:27:00.544321Z",
          "iopub.execute_input": "2025-11-19T13:27:00.54466Z",
          "iopub.status.idle": "2025-11-19T13:27:00.59356Z",
          "shell.execute_reply.started": "2025-11-19T13:27:00.544636Z",
          "shell.execute_reply": "2025-11-19T13:27:00.591936Z"
        },
        "id": "01NVe4TZVcZj",
        "outputId": "b0d4dfeb-689f-47e8-a028-c16153ca80fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-11-19 13:42:16.674 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-19 13:42:16.675 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-19 13:42:16.677 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-19 13:42:16.679 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-19 13:42:16.680 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-19 13:42:16.682 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-19 13:42:16.683 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-19 13:42:16.684 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-19 13:42:16.684 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-19 13:42:16.687 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-19 13:42:16.687 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-19 13:42:16.688 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-19 13:42:16.689 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-19 13:42:16.690 Session state does not function when running a script without `streamlit run`\n",
            "2025-11-19 13:42:16.691 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-19 13:42:16.695 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-19 13:42:16.695 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-19 13:42:16.696 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-19 13:42:16.696 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-19 13:42:16.698 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-19 13:42:16.699 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-19 13:42:16.701 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-19 13:42:16.702 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-19 13:42:16.703 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-19 13:42:16.705 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-19 13:42:16.706 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-19 13:42:16.708 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-19 13:42:16.709 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-19 13:42:16.712 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-19 13:42:16.712 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-19 13:42:16.714 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-19 13:42:16.716 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-19 13:42:16.717 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-19 13:42:16.718 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-19 13:42:16.720 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-19 13:42:16.721 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-19 13:42:16.721 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-19 13:42:16.722 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-19 13:42:16.723 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-19 13:42:16.724 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-19 13:42:16.727 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-19 13:42:16.728 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ],
      "execution_count": 19
    },
    {
      "cell_type": "code",
      "source": [
        "if run_train:\n",
        "    if not os.path.exists(dataset_path):\n",
        "        st.error('Dataset path not found. Please ensure the dataset is mounted (e.g., in Kaggle input) and the path is correct.')\n",
        "    else:\n",
        "        output = st.text_input('Output checkpoint path', value='./nationality_model.pth')\n",
        "        epochs = st.number_input('Epochs', value=3, min_value=1, max_value=100)\n",
        "        batch_size = st.number_input('Batch size', value=32, min_value=8, max_value=256)\n",
        "        st.write('Starting training... open logs below')\n",
        "        try:\n",
        "            train_nationality_classifier(dataset_path, output, epochs=int(epochs), batch_size=int(batch_size))\n",
        "            st.success('Training finished — checkpoint saved')\n",
        "        except Exception as e:\n",
        "            st.error(f'Training failed: {e}')\n",
        "\n",
        "# Load nationality model if possible\n",
        "device = torch.device('cuda' if (torch is not None and torch.cuda.is_available()) else 'cpu')\n",
        "nationality_model = None\n",
        "class_names = []"
      ],
      "metadata": {
        "trusted": true,
        "id": "PAUWNxlaVcZj"
      },
      "outputs": [],
      "execution_count": 20
    },
    {
      "cell_type": "code",
      "source": [
        "if torch is not None and os.path.exists(model_path):\n",
        "    # attempt to load saved checkpoint and classes\n",
        "    try:\n",
        "        ckpt = torch.load(model_path, map_location=device)\n",
        "        if isinstance(ckpt, dict) and 'state_dict' in ckpt and 'classes' in ckpt:\n",
        "            class_names = ckpt['classes']\n",
        "            nationality_model = SimpleNationalityClassifier(len(class_names))\n",
        "            nationality_model.load_state_dict(ckpt['state_dict'])\n",
        "            nationality_model.to(device); nationality_model.eval()\n",
        "        elif isinstance(ckpt, dict) and 'classes' in ckpt and 'state_dict' not in ckpt:\n",
        "            # maybe a straight state_dict with classes appended\n",
        "            class_names = ckpt.get('classes', [])\n",
        "            try:\n",
        "                nationality_model = SimpleNationalityClassifier(len(class_names))\n",
        "                nationality_model.load_state_dict(ckpt['state_dict'])\n",
        "                nationality_model.to(device); nationality_model.eval()\n",
        "            except Exception:\n",
        "                nationality_model = None\n",
        "        else:\n",
        "            # try partial heuristics\n",
        "            nationality_model = load_nationality_model(model_path, device, num_classes=10)\n",
        "    except Exception as e:\n",
        "        st.warning(f'Could not load nationality model: {e}')\n",
        "\n",
        "american_list_str = st.text_input('Comma-separated list of American nationalities to treat specially', value='Brazil,Spain,American,Thailand')\n",
        "american_list = [x.strip().lower() for x in american_list_str.split(',') if x.strip()]\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-19T13:30:31.260562Z",
          "iopub.execute_input": "2025-11-19T13:30:31.26092Z",
          "iopub.status.idle": "2025-11-19T13:30:31.276329Z",
          "shell.execute_reply.started": "2025-11-19T13:30:31.260878Z",
          "shell.execute_reply": "2025-11-19T13:30:31.275369Z"
        },
        "id": "he7SuLBiVcZk",
        "outputId": "6dfe695f-360d-4d9c-b3e6-678bdaad6a34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-11-19 13:42:40.824 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-19 13:42:40.825 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-19 13:42:40.829 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-19 13:42:40.830 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-19 13:42:40.833 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-19 13:42:40.838 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-19 13:42:40.840 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ],
      "execution_count": 22
    },
    {
      "cell_type": "code",
      "source": [
        "if uploaded is not None:\n",
        "    image = Image.open(uploaded).convert('RGB')\n",
        "    st.subheader('Input preview')\n",
        "    st.image(image, use_column_width=True)\n",
        "\n",
        "    # Convert to cv2 BGR\n",
        "    img_bgr = pil_to_cv2(image)\n",
        "    faces = detect_faces(img_bgr)\n",
        "    if len(faces) == 0:\n",
        "        st.warning('No faces detected. Try a different image or ensure the face is visible.')\n",
        "    else:\n",
        "        st.success(f'Detected {len(faces)} face(s) — showing results for the first face')\n",
        "        box = faces[0]\n",
        "        face_crop = crop_region(img_bgr, box, pad=0.25)\n",
        "        st.image(cv2_to_pil(face_crop), caption='Detected face crop')\n",
        "\n",
        "        # Predict nationality (using model if available), else fallback to Unknown\n",
        "        nationality = 'Unknown'\n",
        "        nat_conf = 0.0\n",
        "        if nationality_model is not None and class_names:\n",
        "            face_pil = cv2_to_pil(face_crop)\n",
        "            nationality, nat_conf = predict_nationality_from_image(nationality_model, device, face_pil, class_names)\n",
        "        else:\n",
        "            st.info('Nationality model not found — you can train one or provide a model path.')\n",
        "\n",
        "        # Predict emotion & age with DeepFace if available\n",
        "        emotion, age, deepface_raw = predict_emotion_age_deepface(cv2_to_pil(face_crop))\n",
        "        if DeepFace is None:\n",
        "            st.info('DeepFace not available. Age and emotion predictions require installing deepface. Falling back to heuristics (not implemented).')\n",
        "            # Clothing/dress color: crop a region below the face box (approximate torso)\n",
        "        x,y,w,h = box\n",
        "        H,W = img_bgr.shape[:2]\n",
        "        torso_y0 = y + int(0.9*h)\n",
        "        torso_y1 = min(H, y + int(3.5*h))\n",
        "        torso_x0 = max(0, x - int(0.5*w))\n",
        "        torso_x1 = min(W, x + int(1.5*w))\n",
        "        if torso_y0 < torso_y1 and torso_x0 < torso_x1:\n",
        "            torso = img_bgr[torso_y0:torso_y1, torso_x0:torso_x1]\n",
        "            if torso.size == 0:\n",
        "                dress_color_name = 'Unknown'\n",
        "                dress_rgb = (0,0,0)\n",
        "            else:\n",
        "                dress_rgb = get_dominant_color(torso, k=3)\n",
        "                dress_color_name = rgb_to_name(dress_rgb)\n",
        "            st.image(cv2_to_pil(torso), caption='Estimated torso region (for dress color)')\n",
        "        else:\n",
        "            dress_color_name = 'Unknown'\n",
        "            dress_rgb = (0,0,0)\n",
        "\n",
        "        # Decide which outputs to display depending on nationality\n",
        "        nat_lower = nationality.lower() if isinstance(nationality, str) else ''\n",
        "        st.subheader('Predictions')\n",
        "        col_a, col_b = st.columns(2)\n",
        "        with col_a:\n",
        "            st.write('**Nationality**')\n",
        "            st.write(f'{nationality} (confidence {nat_conf:.2f})')\n",
        "        with col_b:\n",
        "            st.write('**Emotion**')\n",
        "            st.write(f'{emotion if emotion is not None else \"Unknown\"}')\n",
        "\n",
        "        # conditional\n",
        "        if 'indian' in nat_lower or nationality.strip().lower() == 'india':\n",
        "            st.write('**Additional outputs for Indian nationality**')\n",
        "            st.write(f'Age: {age if age is not None else \"Unknown (DeepFace not available)\"}')\n",
        "            st.write(f'Dress color: {dress_color_name} RGB{dress_rgb}')\n",
        "        elif nat_lower in ['usa', 'united states', 'united states of america', 'us'] or 'united states' in nat_lower:\n",
        "            st.write('**US individual: show age & emotion**')\n",
        "            st.write(f'Age: {age if age is not None else \"Unknown (DeepFace not available)\"}')\n",
        "        elif nat_lower in african_list:\n",
        "            st.write('**Spain individual selected: show emotion & dress color**')\n",
        "            st.write(f'Dress color: {dress_color_name} RGB{dress_rgb}')\n",
        "        else:\n",
        "            st.write('**Default output (other nationalities): nationality & emotion**')\n",
        "\n",
        "        # Show raw DeepFace output if user wants\n",
        "        if deepface_raw:\n",
        "            with st.expander('Show DeepFace raw output'):\n",
        "                st.write(deepface_raw)\n",
        "\n",
        "        # Allow download of results as CSV\n",
        "        import pandas as pd\n",
        "        results = {\n",
        "            'filename': uploaded.name,\n",
        "            'nationality': nationality,\n",
        "            'nationality_conf': nat_conf,\n",
        "            'emotion': emotion,\n",
        "            'age': age,\n",
        "            'dress_color_name': dress_color_name,\n",
        "            'dress_color_rgb': str(dress_rgb)\n",
        "        }\n",
        "        df = pd.DataFrame([results])\n",
        "        csv = df.to_csv(index=False).encode('utf-8')\n",
        "        st.download_button('Download results CSV', data=csv, file_name='prediction_results.csv', mime='text/csv')\n",
        "\n",
        "st.markdown('---')\n",
        "st.subheader('Notes & next steps')\n",
        "st.markdown('''\n",
        "- This app is a template. For production use:\n",
        "  - Train a robust nationality classifier on the provided dataset and place the checkpoint path in the model input.\n",
        "  - Use a stronger face detector (MTCNN or RetinaFace) for better detection accuracy.\n",
        "  - Consider privacy and ethical implications: predicting nationality from appearance can be inaccurate and harmful. Use responsibly and with informed consent.\n",
        "- To install dependencies: `pip install streamlit torch torchvision opencv-python-headless deepface scikit-learn`\n",
        "''')\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "WTOpNIKXVcZk",
        "outputId": "24374aee-8ebe-41c7-eefc-fb083deebbde",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-11-19 13:42:45.196 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-19 13:42:45.198 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-19 13:42:45.198 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-19 13:42:45.199 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-19 13:42:45.200 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-19 13:42:45.201 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-19 13:42:45.202 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-19 13:42:45.203 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-19 13:42:45.204 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeltaGenerator()"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "execution_count": 23
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "x9qCym2YVcZl"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}